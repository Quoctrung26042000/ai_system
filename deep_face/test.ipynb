{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from deepface import DeepFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_features(img_path):\n",
    "  embedding_objs = DeepFace.represent(img_path, model_name='Facenet512', enforce_detection=False)\n",
    "  return embedding_objs[0]['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HTMVan.10B1', 'TCTai.10B1', 'PPTuan.10B1', 'NDTAnh.10B1', 'HDAKiet.10B1', 'TCNNam.10B1', 'PTTHa.10B1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:12<00:00,  1.72s/it]\n"
     ]
    }
   ],
   "source": [
    "root = '/home/ubuntu/ai_attendance_system/deepface/data_face'\n",
    "data = []\n",
    "dirs = os.listdir(root)\n",
    "print(dirs)\n",
    "for dir in tqdm(dirs):\n",
    "  for img in os.listdir(os.path.join(root, dir)):\n",
    "     features = extract_features(os.path.join(root, dir, img))\n",
    "     features.insert(0, dir)\n",
    "     data.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person name</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f503</th>\n",
       "      <th>f504</th>\n",
       "      <th>f505</th>\n",
       "      <th>f506</th>\n",
       "      <th>f507</th>\n",
       "      <th>f508</th>\n",
       "      <th>f509</th>\n",
       "      <th>f510</th>\n",
       "      <th>f511</th>\n",
       "      <th>f512</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HTMVan.10B1</td>\n",
       "      <td>0.322058</td>\n",
       "      <td>-0.433161</td>\n",
       "      <td>-0.672233</td>\n",
       "      <td>0.686782</td>\n",
       "      <td>-0.239042</td>\n",
       "      <td>0.528821</td>\n",
       "      <td>-0.515339</td>\n",
       "      <td>0.269433</td>\n",
       "      <td>-0.235005</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.153020</td>\n",
       "      <td>0.075565</td>\n",
       "      <td>-0.272968</td>\n",
       "      <td>0.273718</td>\n",
       "      <td>0.294176</td>\n",
       "      <td>0.196406</td>\n",
       "      <td>0.295513</td>\n",
       "      <td>0.115156</td>\n",
       "      <td>0.034416</td>\n",
       "      <td>-0.239489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HTMVan.10B1</td>\n",
       "      <td>-0.799124</td>\n",
       "      <td>0.649721</td>\n",
       "      <td>-1.067423</td>\n",
       "      <td>1.807344</td>\n",
       "      <td>0.254739</td>\n",
       "      <td>-0.177150</td>\n",
       "      <td>-0.582705</td>\n",
       "      <td>0.131899</td>\n",
       "      <td>-0.022124</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000305</td>\n",
       "      <td>-0.628453</td>\n",
       "      <td>-1.339539</td>\n",
       "      <td>1.494982</td>\n",
       "      <td>-0.879591</td>\n",
       "      <td>0.565622</td>\n",
       "      <td>1.095937</td>\n",
       "      <td>-0.650479</td>\n",
       "      <td>0.758743</td>\n",
       "      <td>-0.012012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HTMVan.10B1</td>\n",
       "      <td>-0.494682</td>\n",
       "      <td>0.468054</td>\n",
       "      <td>-1.165669</td>\n",
       "      <td>1.400342</td>\n",
       "      <td>0.095167</td>\n",
       "      <td>-0.615882</td>\n",
       "      <td>-0.052469</td>\n",
       "      <td>-0.175951</td>\n",
       "      <td>-0.743183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024124</td>\n",
       "      <td>-0.445072</td>\n",
       "      <td>-1.593938</td>\n",
       "      <td>1.555155</td>\n",
       "      <td>-1.084509</td>\n",
       "      <td>0.877635</td>\n",
       "      <td>1.105216</td>\n",
       "      <td>-0.701744</td>\n",
       "      <td>0.424702</td>\n",
       "      <td>0.208243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HTMVan.10B1</td>\n",
       "      <td>0.045172</td>\n",
       "      <td>-0.712837</td>\n",
       "      <td>-1.211775</td>\n",
       "      <td>0.617426</td>\n",
       "      <td>-0.491368</td>\n",
       "      <td>-0.414576</td>\n",
       "      <td>-0.231331</td>\n",
       "      <td>0.170432</td>\n",
       "      <td>0.065418</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.674945</td>\n",
       "      <td>1.091405</td>\n",
       "      <td>-0.310416</td>\n",
       "      <td>0.427969</td>\n",
       "      <td>0.120300</td>\n",
       "      <td>-0.435138</td>\n",
       "      <td>-0.545808</td>\n",
       "      <td>0.412314</td>\n",
       "      <td>0.128153</td>\n",
       "      <td>-0.313113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HTMVan.10B1</td>\n",
       "      <td>-0.703672</td>\n",
       "      <td>0.678344</td>\n",
       "      <td>-1.159584</td>\n",
       "      <td>1.581358</td>\n",
       "      <td>0.286007</td>\n",
       "      <td>-0.368840</td>\n",
       "      <td>-0.169128</td>\n",
       "      <td>-0.048448</td>\n",
       "      <td>-0.908420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.229358</td>\n",
       "      <td>-0.605996</td>\n",
       "      <td>-1.726386</td>\n",
       "      <td>1.940127</td>\n",
       "      <td>-0.327482</td>\n",
       "      <td>1.084144</td>\n",
       "      <td>0.538159</td>\n",
       "      <td>-1.262533</td>\n",
       "      <td>0.400448</td>\n",
       "      <td>0.192428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 513 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   person name        f1        f2        f3        f4        f5        f6  \\\n",
       "0  HTMVan.10B1  0.322058 -0.433161 -0.672233  0.686782 -0.239042  0.528821   \n",
       "1  HTMVan.10B1 -0.799124  0.649721 -1.067423  1.807344  0.254739 -0.177150   \n",
       "2  HTMVan.10B1 -0.494682  0.468054 -1.165669  1.400342  0.095167 -0.615882   \n",
       "3  HTMVan.10B1  0.045172 -0.712837 -1.211775  0.617426 -0.491368 -0.414576   \n",
       "4  HTMVan.10B1 -0.703672  0.678344 -1.159584  1.581358  0.286007 -0.368840   \n",
       "\n",
       "         f7        f8        f9  ...      f503      f504      f505      f506  \\\n",
       "0 -0.515339  0.269433 -0.235005  ... -0.153020  0.075565 -0.272968  0.273718   \n",
       "1 -0.582705  0.131899 -0.022124  ... -0.000305 -0.628453 -1.339539  1.494982   \n",
       "2 -0.052469 -0.175951 -0.743183  ...  0.024124 -0.445072 -1.593938  1.555155   \n",
       "3 -0.231331  0.170432  0.065418  ... -0.674945  1.091405 -0.310416  0.427969   \n",
       "4 -0.169128 -0.048448 -0.908420  ...  0.229358 -0.605996 -1.726386  1.940127   \n",
       "\n",
       "       f507      f508      f509      f510      f511      f512  \n",
       "0  0.294176  0.196406  0.295513  0.115156  0.034416 -0.239489  \n",
       "1 -0.879591  0.565622  1.095937 -0.650479  0.758743 -0.012012  \n",
       "2 -1.084509  0.877635  1.105216 -0.701744  0.424702  0.208243  \n",
       "3  0.120300 -0.435138 -0.545808  0.412314  0.128153 -0.313113  \n",
       "4 -0.327482  1.084144  0.538159 -1.262533  0.400448  0.192428  \n",
       "\n",
       "[5 rows x 513 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = ['person name']\n",
    "for i in range(512):\n",
    "  column_names.append(f'f{i+1}')\n",
    "\n",
    "df_org = pd.DataFrame(data, columns=column_names)\n",
    "df_org.to_csv('face_features.csv', index=False)\n",
    "df_org.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person name</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f503</th>\n",
       "      <th>f504</th>\n",
       "      <th>f505</th>\n",
       "      <th>f506</th>\n",
       "      <th>f507</th>\n",
       "      <th>f508</th>\n",
       "      <th>f509</th>\n",
       "      <th>f510</th>\n",
       "      <th>f511</th>\n",
       "      <th>f512</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>0.415207</td>\n",
       "      <td>-0.386182</td>\n",
       "      <td>-0.761581</td>\n",
       "      <td>1.765350</td>\n",
       "      <td>-0.089976</td>\n",
       "      <td>0.127776</td>\n",
       "      <td>-0.878439</td>\n",
       "      <td>0.434871</td>\n",
       "      <td>0.394741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533462</td>\n",
       "      <td>-1.782721</td>\n",
       "      <td>-1.069523</td>\n",
       "      <td>1.544035</td>\n",
       "      <td>-0.665312</td>\n",
       "      <td>0.594126</td>\n",
       "      <td>-0.130272</td>\n",
       "      <td>-1.246574</td>\n",
       "      <td>-0.258193</td>\n",
       "      <td>-0.434187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>1.269337</td>\n",
       "      <td>0.391684</td>\n",
       "      <td>0.524789</td>\n",
       "      <td>2.250469</td>\n",
       "      <td>1.596831</td>\n",
       "      <td>0.101942</td>\n",
       "      <td>-0.982712</td>\n",
       "      <td>-0.360430</td>\n",
       "      <td>0.127809</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.836020</td>\n",
       "      <td>-0.980137</td>\n",
       "      <td>-0.671515</td>\n",
       "      <td>1.548209</td>\n",
       "      <td>0.084967</td>\n",
       "      <td>1.098884</td>\n",
       "      <td>0.479823</td>\n",
       "      <td>-1.366727</td>\n",
       "      <td>1.329335</td>\n",
       "      <td>-0.765459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>6</td>\n",
       "      <td>0.065413</td>\n",
       "      <td>-0.187295</td>\n",
       "      <td>-1.038659</td>\n",
       "      <td>1.538978</td>\n",
       "      <td>-0.293485</td>\n",
       "      <td>0.406746</td>\n",
       "      <td>-0.348509</td>\n",
       "      <td>0.684315</td>\n",
       "      <td>-0.318287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325161</td>\n",
       "      <td>0.523756</td>\n",
       "      <td>-0.721655</td>\n",
       "      <td>-0.184646</td>\n",
       "      <td>-0.015526</td>\n",
       "      <td>0.533285</td>\n",
       "      <td>0.616137</td>\n",
       "      <td>-0.227958</td>\n",
       "      <td>-0.162661</td>\n",
       "      <td>-0.050137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>6</td>\n",
       "      <td>1.190615</td>\n",
       "      <td>-0.271401</td>\n",
       "      <td>-0.603150</td>\n",
       "      <td>1.718566</td>\n",
       "      <td>-0.408453</td>\n",
       "      <td>-0.944755</td>\n",
       "      <td>-0.986922</td>\n",
       "      <td>0.457718</td>\n",
       "      <td>-0.744641</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.107196</td>\n",
       "      <td>-0.692395</td>\n",
       "      <td>-0.864722</td>\n",
       "      <td>0.875340</td>\n",
       "      <td>-0.775757</td>\n",
       "      <td>-0.057353</td>\n",
       "      <td>-0.884720</td>\n",
       "      <td>-1.016677</td>\n",
       "      <td>2.120405</td>\n",
       "      <td>-0.331296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.297778</td>\n",
       "      <td>0.712079</td>\n",
       "      <td>-1.237908</td>\n",
       "      <td>1.002707</td>\n",
       "      <td>-0.435174</td>\n",
       "      <td>-0.874092</td>\n",
       "      <td>-0.535254</td>\n",
       "      <td>0.903722</td>\n",
       "      <td>0.565182</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.610860</td>\n",
       "      <td>-0.238660</td>\n",
       "      <td>-0.984327</td>\n",
       "      <td>-0.053598</td>\n",
       "      <td>-1.631189</td>\n",
       "      <td>1.065352</td>\n",
       "      <td>0.878357</td>\n",
       "      <td>-1.644465</td>\n",
       "      <td>0.052931</td>\n",
       "      <td>-0.355536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 513 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    person name        f1        f2        f3        f4        f5        f6  \\\n",
       "18            3  0.415207 -0.386182 -0.761581  1.765350 -0.089976  0.127776   \n",
       "29            5  1.269337  0.391684  0.524789  2.250469  1.596831  0.101942   \n",
       "31            6  0.065413 -0.187295 -1.038659  1.538978 -0.293485  0.406746   \n",
       "30            6  1.190615 -0.271401 -0.603150  1.718566 -0.408453 -0.944755   \n",
       "23            4 -0.297778  0.712079 -1.237908  1.002707 -0.435174 -0.874092   \n",
       "\n",
       "          f7        f8        f9  ...      f503      f504      f505      f506  \\\n",
       "18 -0.878439  0.434871  0.394741  ...  0.533462 -1.782721 -1.069523  1.544035   \n",
       "29 -0.982712 -0.360430  0.127809  ... -0.836020 -0.980137 -0.671515  1.548209   \n",
       "31 -0.348509  0.684315 -0.318287  ...  0.325161  0.523756 -0.721655 -0.184646   \n",
       "30 -0.986922  0.457718 -0.744641  ... -2.107196 -0.692395 -0.864722  0.875340   \n",
       "23 -0.535254  0.903722  0.565182  ... -0.610860 -0.238660 -0.984327 -0.053598   \n",
       "\n",
       "        f507      f508      f509      f510      f511      f512  \n",
       "18 -0.665312  0.594126 -0.130272 -1.246574 -0.258193 -0.434187  \n",
       "29  0.084967  1.098884  0.479823 -1.366727  1.329335 -0.765459  \n",
       "31 -0.015526  0.533285  0.616137 -0.227958 -0.162661 -0.050137  \n",
       "30 -0.775757 -0.057353 -0.884720 -1.016677  2.120405 -0.331296  \n",
       "23 -1.631189  1.065352  0.878357 -1.644465  0.052931 -0.355536  \n",
       "\n",
       "[5 rows x 513 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_org.replace(dirs, [i for i in range(len(dirs))])\n",
    "df = df.sample(frac=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cut = round(len(df) * .8)\n",
    "\n",
    "x_train = df.iloc[ :cut , 1:]\n",
    "y_train = df['person name'][ :cut]\n",
    "x_test = df.iloc[cut: , 1:]\n",
    "y_test = df['person name'][cut: ]\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1/1 [==============================] - 1s 578ms/step - loss: 1.9301 - accuracy: 0.2500 - val_loss: 1.8190 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.6433 - accuracy: 0.4286 - val_loss: 1.7393 - val_accuracy: 0.2857\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.4405 - accuracy: 0.6429 - val_loss: 1.6877 - val_accuracy: 0.4286\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.2877 - accuracy: 0.7500 - val_loss: 1.6448 - val_accuracy: 0.4286\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.1635 - accuracy: 0.7857 - val_loss: 1.6112 - val_accuracy: 0.4286\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.0610 - accuracy: 0.8571 - val_loss: 1.5823 - val_accuracy: 0.4286\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.9739 - accuracy: 0.8571 - val_loss: 1.5574 - val_accuracy: 0.4286\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9011 - accuracy: 0.8571 - val_loss: 1.5359 - val_accuracy: 0.4286\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8419 - accuracy: 0.8571 - val_loss: 1.5179 - val_accuracy: 0.4286\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7903 - accuracy: 0.8571 - val_loss: 1.5005 - val_accuracy: 0.4286\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7449 - accuracy: 0.8571 - val_loss: 1.4833 - val_accuracy: 0.4286\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7040 - accuracy: 0.8571 - val_loss: 1.4669 - val_accuracy: 0.4286\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6674 - accuracy: 0.8929 - val_loss: 1.4508 - val_accuracy: 0.4286\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6349 - accuracy: 0.8929 - val_loss: 1.4357 - val_accuracy: 0.4286\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6057 - accuracy: 0.9286 - val_loss: 1.4220 - val_accuracy: 0.4286\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5794 - accuracy: 0.9286 - val_loss: 1.4095 - val_accuracy: 0.4286\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5554 - accuracy: 0.9286 - val_loss: 1.3972 - val_accuracy: 0.4286\n",
      "Epoch 18/60\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5333 - accuracy: 0.9286 - val_loss: 1.3867 - val_accuracy: 0.4286\n",
      "Epoch 19/60\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5131 - accuracy: 0.9286 - val_loss: 1.3779 - val_accuracy: 0.4286\n",
      "Epoch 20/60\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4946 - accuracy: 0.9286 - val_loss: 1.3702 - val_accuracy: 0.4286\n",
      "Epoch 21/60\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4777 - accuracy: 0.9643 - val_loss: 1.3637 - val_accuracy: 0.4286\n",
      "Epoch 22/60\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4618 - accuracy: 0.9643 - val_loss: 1.3583 - val_accuracy: 0.4286\n",
      "Epoch 23/60\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4470 - accuracy: 1.0000 - val_loss: 1.3540 - val_accuracy: 0.4286\n",
      "Epoch 24/60\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4330 - accuracy: 1.0000 - val_loss: 1.3510 - val_accuracy: 0.4286\n",
      "Epoch 25/60\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4194 - accuracy: 1.0000 - val_loss: 1.3494 - val_accuracy: 0.4286\n",
      "Epoch 26/60\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4063 - accuracy: 1.0000 - val_loss: 1.3488 - val_accuracy: 0.4286\n",
      "Epoch 27/60\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.3940 - accuracy: 1.0000 - val_loss: 1.3486 - val_accuracy: 0.4286\n",
      "Epoch 28/60\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.3824 - accuracy: 1.0000 - val_loss: 1.3481 - val_accuracy: 0.4286\n",
      "Epoch 29/60\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3714 - accuracy: 1.0000 - val_loss: 1.3476 - val_accuracy: 0.4286\n",
      "Epoch 30/60\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3608 - accuracy: 1.0000 - val_loss: 1.3472 - val_accuracy: 0.4286\n",
      "Epoch 31/60\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3507 - accuracy: 1.0000 - val_loss: 1.3466 - val_accuracy: 0.4286\n",
      "Epoch 32/60\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.3410 - accuracy: 1.0000 - val_loss: 1.3457 - val_accuracy: 0.4286\n",
      "Epoch 33/60\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3317 - accuracy: 1.0000 - val_loss: 1.3443 - val_accuracy: 0.4286\n",
      "Epoch 34/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3228 - accuracy: 1.0000 - val_loss: 1.3422 - val_accuracy: 0.4286\n",
      "Epoch 35/60\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3143 - accuracy: 1.0000 - val_loss: 1.3395 - val_accuracy: 0.4286\n",
      "Epoch 36/60\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3060 - accuracy: 1.0000 - val_loss: 1.3367 - val_accuracy: 0.4286\n",
      "Epoch 37/60\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2980 - accuracy: 1.0000 - val_loss: 1.3339 - val_accuracy: 0.4286\n",
      "Epoch 38/60\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2904 - accuracy: 1.0000 - val_loss: 1.3315 - val_accuracy: 0.4286\n",
      "Epoch 39/60\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2830 - accuracy: 1.0000 - val_loss: 1.3298 - val_accuracy: 0.4286\n",
      "Epoch 40/60\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2758 - accuracy: 1.0000 - val_loss: 1.3292 - val_accuracy: 0.4286\n",
      "Epoch 41/60\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2689 - accuracy: 1.0000 - val_loss: 1.3293 - val_accuracy: 0.4286\n",
      "Epoch 42/60\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2621 - accuracy: 1.0000 - val_loss: 1.3297 - val_accuracy: 0.4286\n",
      "Epoch 43/60\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2555 - accuracy: 1.0000 - val_loss: 1.3299 - val_accuracy: 0.4286\n",
      "Epoch 44/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2492 - accuracy: 1.0000 - val_loss: 1.3301 - val_accuracy: 0.4286\n",
      "Epoch 45/60\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2430 - accuracy: 1.0000 - val_loss: 1.3300 - val_accuracy: 0.4286\n",
      "Epoch 46/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2370 - accuracy: 1.0000 - val_loss: 1.3297 - val_accuracy: 0.4286\n",
      "Epoch 47/60\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2312 - accuracy: 1.0000 - val_loss: 1.3292 - val_accuracy: 0.4286\n",
      "Epoch 48/60\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2256 - accuracy: 1.0000 - val_loss: 1.3287 - val_accuracy: 0.4286\n",
      "Epoch 49/60\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2202 - accuracy: 1.0000 - val_loss: 1.3281 - val_accuracy: 0.4286\n",
      "Epoch 50/60\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2150 - accuracy: 1.0000 - val_loss: 1.3276 - val_accuracy: 0.4286\n",
      "Epoch 51/60\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2101 - accuracy: 1.0000 - val_loss: 1.3274 - val_accuracy: 0.4286\n",
      "Epoch 52/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2052 - accuracy: 1.0000 - val_loss: 1.3275 - val_accuracy: 0.4286\n",
      "Epoch 53/60\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2004 - accuracy: 1.0000 - val_loss: 1.3274 - val_accuracy: 0.4286\n",
      "Epoch 54/60\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1958 - accuracy: 1.0000 - val_loss: 1.3273 - val_accuracy: 0.4286\n",
      "Epoch 55/60\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1913 - accuracy: 1.0000 - val_loss: 1.3269 - val_accuracy: 0.4286\n",
      "Epoch 56/60\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1869 - accuracy: 1.0000 - val_loss: 1.3264 - val_accuracy: 0.4286\n",
      "Epoch 57/60\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1826 - accuracy: 1.0000 - val_loss: 1.3264 - val_accuracy: 0.4286\n",
      "Epoch 58/60\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1785 - accuracy: 1.0000 - val_loss: 1.3265 - val_accuracy: 0.4286\n",
      "Epoch 59/60\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1744 - accuracy: 1.0000 - val_loss: 1.3266 - val_accuracy: 0.4286\n",
      "Epoch 60/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1705 - accuracy: 1.0000 - val_loss: 1.3271 - val_accuracy: 0.4286\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(1024, 'tanh', input_shape=(512,)),\n",
    "    tf.keras.layers.Dense(256, 'relu'),\n",
    "    tf.keras.layers.Dense(64, 'relu'),\n",
    "    tf.keras.layers.Dense(len(dirs), 'softmax')\n",
    "])\n",
    "model.compile(tf.keras.optimizers.Adamax(.0001), 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "output = model.fit(x_train, y_train, epochs=60, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('weights/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vector1 = extract_features('kiet.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n",
      "The predicted class is 4 with a confidence of 57.65%\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "HDAKiet.10B1\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict([feature_vector1])\n",
    "\n",
    "# Get the index of the class with the highest probability\n",
    "predicted_class = np.argmax(prediction)\n",
    "\n",
    "# Get the confidence level (probability) of the predicted class\n",
    "confidence = prediction[0][predicted_class] * 100 \n",
    "print(f\"The predicted class is {predicted_class} with a confidence of {confidence:.2f}%\")\n",
    "print(dirs[np.argmax(model.predict([feature_vector1]))])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
